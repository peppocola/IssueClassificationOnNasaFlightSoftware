# RoBERTa Model Configuration

# Model
base_model: "roberta-base"

# Training
random_seed: 42
max_length: 512
truncation: true
padding: "max_length"
per_device_train_batch_size: 16
num_train_epochs: 15
save_strategy: "epoch"
evaluation_strategy: "epoch"
metric_for_best_model: "f1_macro"
load_best_model_at_end: true

# Validation
use_validation: true
validation_split: 0.1  # Only used if use_validation is true and no separate validation set is provided

# Custom Loss (optional)
use_custom_loss: false
class_weights: [1.0, 1.0]

# Optimizer
learning_rate: 2e-5
weight_decay: 0.01

# Output
output_dir: "./roberta_output"
logging_dir: "./logs"
